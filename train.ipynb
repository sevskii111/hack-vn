{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from fastai.text.all import *\n",
    "from utils import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seq_len = 400\n",
    "batch_size = 128"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_train = get_dataset()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "parsed_train = parse_docs(dataset_train)\n",
    "parsed_train = [el for el in parsed_train if el is not None]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def one_hot_encode_factor(factor):\n",
    "    result = []\n",
    "    for pp in factor[1]:\n",
    "        s = factor[0] + pp\n",
    "        result.append(s)\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def npa_to_items(npa):\n",
    "    factors_tree = {}\n",
    "    for f in npa[2]:\n",
    "        factors_tree[f[2]] = one_hot_encode_factor(f)\n",
    "    items = []\n",
    "    for doc in parse_npa(docx.Document(npa[1])):\n",
    "        for point, point_text in doc.items():\n",
    "            point_factors = factors_tree.get(point.strip(' .'), '')\n",
    "            items.append((str(npa[1]), '\\n'.join(point_text), ','.join(point_factors)))\n",
    "    return items"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_items_orig = []\n",
    "with Pool(32) as p:\n",
    "        all_items_orig += list(tqdm(p.imap(npa_to_items, parsed_train), total=len(parsed_train)))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_items = []\n",
    "for el in all_items_orig:\n",
    "    all_items += el"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train = pd.DataFrame(all_items, columns=['name', 'text', 'factors'])\n",
    "#df_train['is_valid'] = False\n",
    "#df_test['is_valid'] = True\n",
    "\n",
    "df = df_train#pd.concat([df_train, df_test], ignore_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def filter_df(df, no_corr_coef=1.):\n",
    "    corr = df[df['factors'].str.len() > 0]\n",
    "    no_corr = df[df['factors'].str.len() == 0].sample(int(len(corr) * no_corr_coef), random_state=42)\n",
    "    return pd.concat([corr, no_corr], ignore_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('./models/vocab.pkl', 'rb') as vocab_file:\n",
    "    vocab = pickle.load(vocab_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dblock = DataBlock(\n",
    "    blocks=(TextBlock.from_df('text', seq_len=seq_len, vocab=vocab), MultiCategoryBlock),\n",
    "    get_x=ColReader('text'), get_y=ColReader('factors', label_delim=','), splitter=RandomSplitter(0.2))\n",
    "\n",
    "dls = dblock.dataloaders(filter_df(df, 0.5), bs=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, \n",
    "                                metrics=(accuracy_multi, F1ScoreMulti(), PrecisionMulti(), RecallMulti()), seq_len=seq_len, pretrained=False).to_fp16()\n",
    "learn.unfreeze()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "learn = learn.load_encoder('finetuned')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "learn.lr_find()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "learn.fit_one_cycle(50, 0.004)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds = learn.get_preds()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "v = learn.dls.vocab[1]\n",
    "factor_results = {}\n",
    "for f in v:\n",
    "    factor_results[f] = {'gt': [], 'prob': [], 'pred': []}\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "counts = {}\n",
    "pds, gts = preds\n",
    "for p, g in zip(pds, gts):\n",
    "    for p, gt, factor in zip(p, g, v):\n",
    "        factor_results[factor]['gt'].append(gt.item())\n",
    "        factor_results[factor]['prob'].append(p.item())\n",
    "        factor_results[factor]['pred'].append(int(p > threshold))\n",
    "        if p > threshold:\n",
    "            counts[factor] = counts.get(factor, 0) + 1\n",
    "print(sorted(counts.items()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "report = []\n",
    "for factor_name, factor_result in factor_results.items():\n",
    "    gpred = (factor_result['gt'], factor_result['pred'])\n",
    "    gprob = (factor_result['gt'], factor_result['prob'])\n",
    "    report.append((factor_name, f1_score(*gpred), accuracy_score(*gpred), recall_score(*gpred), precision_score(*gpred), roc_auc_score(*gprob)))\n",
    "\n",
    "pd.DataFrame(report, columns=['Фактор', 'F1', 'Accuracy', 'Recall', 'Precision', 'ROCAUC'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "learn.export('./models/model_50')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('hack-vn-prod': conda)"
  },
  "interpreter": {
   "hash": "270901fbbebb00cf957988222ea2576e2f3a602f1445602215db0d4ce7ba34de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}